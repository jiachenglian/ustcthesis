% !TeX root = ../main.tex

\ustcsetup{
  keywords = {
    图神经网络；图神经网络加速器；指令设计；指令生成；指令优化
  },
  keywords* = {
    graph neural network; graph neural network accelerator;instruction design;instruction generation;instruction optimization
  },
}

\begin{abstract}

  神经网络的快速发展带起了机器学习的热潮，各类深度学习算法层见叠出，人们的目光开始从欧几里得结构数据的处理转向非欧几里得结构数据的处理，这时图神经网络的出现提供了新的研究方向。
  与传统神经网络相比，将图神经网络用于处理图数据一般会得到更好的效果。

  目前对于图神经网络的研究集中在算法和硬件加速器上，还没有学术论文讨论图神经网络加速器的相关指令。
  本文先对图卷积网络、GraphSAGE算法、DiffPool算法这三个较为主流的图神经网络算法进行了调研，叙述了各算法详细的计算流程，并在此基础上将三个算法的共性提炼成采样、聚集、组合、池化这四个算子，用以描述算法和作为指令生成的模块。
  接着调研了一种混合结构图神经网络加速器的架构，并决定使用这种架构进行指令生成和优化工作。加速器主要由聚集引擎、组合引擎和协调器组成，分别用于挖掘顶点聚集时的边级并行性、利用脉动阵列处理矩阵运算和协调两个引擎对内存的访问。
  针对前述加速器和算子特性，本文设计了需要用到的指令，并为四个算子和前述三个具体算法生成能在加速器上运行的指令。
  为了提高指令的执行效率，使用软件流水技术优化生成的指令。

\end{abstract}

\begin{enabstract}

  The rapid development of neural network has brought an upsurge of machine learning with various deep learning algorithms emerging.
  People begin to turn their eyes from the process of Euclidean structure data to non-Euclidean structure data, and gnn, namely graph neural network, provides new directions for them.
  Compared to traditional neural network, using gnn to process graph data usually performs better.

  The current researchs on gnn focus on algorithms and hardware accelerators, and no academic papers have been found to discuss instructions of gnn accelerator.
  This paper investigates three mainstream gnn algorithms, graph convolutional network, GraphSAGE algorithm and DiffPool algorithm.
  After describing calculation process of each, I summerize their commonness into four operators, which are sample, aggregation, combination, and pooling, to be modules of instructions generation.
  Then I investigate a gnn accelerator with hybrid architecture, and decide to use it for instruction generation and optimization.
  The accelerator is mainly composed of an aggregation engine, a combination engine and a coordinator, which are used to employ edge-level parallelism during vertex aggregation, perform matrix operations in systolic arrays, and coordinate the memory access of two engines, respectively.
  Based on the characteristics of gnn operators and the accelerator, this paper designs and generates instructions for operators and algorithms.
  At last, software pipeline technique is applied to improve execution efficiency of instructions.

\end{enabstract}
